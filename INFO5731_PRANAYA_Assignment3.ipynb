{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "INFO5731_PRANAYA_Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psameni/INFO5731_Spring2020/blob/master/INFO5731_PRANAYA_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku-T0VSF70jr",
        "colab_type": "code",
        "outputId": "6fa15982-4748-4721-a55a-ceb2ce683e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "#using twitter Authentication to connect to twitter api with twitter provided keys.\n",
        "authentication = tweepy.OAuthHandler('Dpp7E4W9YkKGVszqezpjpSlLc', 'bczWmE17Ve1DJHKJY0Z9eQYuAupPZ63JfL9AGnkuX12SUZkCWJ')\n",
        "authentication.set_access_token('4289066089-Vd6LpZcoLUERdoFJTnk3J12w8M2sgajQ8HDIlaL', 'yebOZX98i8RtrsMNcWrLBh54K6ypZXi3KejgXSzunyxnH')\n",
        "api = tweepy.API(authentication,wait_on_rate_limit=True)\n",
        "\n",
        "#file operation\n",
        "csvFile = open('tagdata.csv', 'w')\n",
        "data = pd.read_csv('tagdata.csv', names=['tweet_data'], header=None)\n",
        "write_to_csv = csv.writer(csvFile)\n",
        "\n",
        "#writing to file using csvwriter\n",
        "for tweet_data in tweepy.Cursor(api.search,q=\"#wuhancoronavirus\",lang=\"en\").items(100):\n",
        "  write_to_csv.writerow([tweet_data.text.encode('utf-8')])\n",
        "#reading csv file \n",
        "data = pd.read_csv('tagdata.csv',error_bad_lines=False,names=['tweet_data'])\n",
        "import string\n",
        "\n",
        "#Removing noise (Punctuation,extra words)\n",
        "data['tweet_data']=data['tweet_data'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "data['tweet_data']=data['tweet_data'].str.replace('[^A-Za-z ]','')\n",
        "data['tweet_data']=data['tweet_data'].str.replace('bRT','')\n",
        "# print(data['tweet_data'].head())\n",
        "\n",
        "#Removing numbers\n",
        "data['tweet_data'] = data['tweet_data'].str.replace('\\d+', '')\n",
        "\n",
        "#Removing StopWords\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "data['tweet_data']=data['tweet_data'].apply(lambda x:\" \".join(y for y in x.split() if y not in stop))\n",
        "\n",
        "\n",
        "#Lower casing\n",
        "data['tweet_data']=data['tweet_data'].str.lower()\n",
        "data2=data[\"tweet_data\"]\n",
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "data['tweet_data']=data['tweet_data'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "#Lemmetization\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "data['tweet_data']=data['tweet_data'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data['tweet_data'].head(5)\n",
        "#saving the formatted sentences to \"Formatted_sentences.txt\"\n",
        "# data['tweet_data'].to_csv(\"Formatted_tweets.csv\",header=\"Tweets\",index=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    rajeevsrinivasa karnataka enforc cordonsanitai...\n",
              "1    nikkimiumiu a hongkong femal polic infect wuha...\n",
              "2    allmui hkpolic use ruler measur distanc tabl b...\n",
              "3    mymonke chinaliedpeopledi nnaround day ago bas...\n",
              "4    rajeevsrinivasa karnataka enforc cordonsanitai...\n",
              "Name: tweet_data, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_tUgqeK70jx",
        "colab_type": "text"
      },
      "source": [
        "### Question 1: Understand N-gram\n",
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the noun phrases and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_7herd-70jy",
        "colab_type": "code",
        "outputId": "2aebfe3f-864f-4b74-c859-fd3f6b1460de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "from textblob import Word,TextBlob\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')#ngram features\n",
        "nltk.download('punkt')\n",
        "for i in range(len(data[\"tweet_data\"])):\n",
        " print(TextBlob(data[\"tweet_data\"][i]).ngrams(3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['nikkimiumiu', 'a', 'hongkong']), WordList(['a', 'hongkong', 'femal']), WordList(['hongkong', 'femal', 'polic']), WordList(['femal', 'polic', 'infect']), WordList(['polic', 'infect', 'wuhancoronaviru']), WordList(['infect', 'wuhancoronaviru', 'reject']), WordList(['wuhancoronaviru', 'reject', 'wear']), WordList(['reject', 'wear', 'mask']), WordList(['wear', 'mask', 'carita']), WordList(['mask', 'carita', 'medic']), WordList(['carita', 'medic', 'centr']), WordList(['medic', 'centr', 'she']), WordList(['centr', 'she', 'cxexxa'])]\n",
            "[WordList(['allmui', 'hkpolic', 'use']), WordList(['hkpolic', 'use', 'ruler']), WordList(['use', 'ruler', 'measur']), WordList(['ruler', 'measur', 'distanc']), WordList(['measur', 'distanc', 'tabl']), WordList(['distanc', 'tabl', 'barnni']), WordList(['tabl', 'barnni', 'think']), WordList(['barnni', 'think', 'hkpolic']), WordList(['think', 'hkpolic', 'workplac']), WordList(['hkpolic', 'workplac', 'restaxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['imshinbei', 'hong', 'kong']), WordList(['hong', 'kong', 'karat']), WordList(['kong', 'karat', 'team']), WordList(['karat', 'team', 'member']), WordList(['team', 'member', 'lee']), WordList(['member', 'lee', 'chunho']), WordList(['lee', 'chunho', 'confirm']), WordList(['chunho', 'confirm', 'wuhancoronaviru']), WordList(['confirm', 'wuhancoronaviru', 'said']), WordList(['wuhancoronaviru', 'said', 'high']), WordList(['said', 'high', 'fever']), WordList(['high', 'fever', 'made']), WordList(['fever', 'made', 'previou']), WordList(['made', 'previou', 'effxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['akshpuranik', 'goa', 'welcom']), WordList(['goa', 'welcom', 'crpfindia']), WordList(['welcom', 'crpfindia', 'nmani']), WordList(['crpfindia', 'nmani', 'peopl']), WordList(['nmani', 'peopl', 'goa']), WordList(['peopl', 'goa', 'seen']), WordList(['goa', 'seen', 'maintain']), WordList(['seen', 'maintain', 'social']), WordList(['maintain', 'social', 'distanc']), WordList(['social', 'distanc', 'shop']), WordList(['distanc', 'shop', 'essenti']), WordList(['shop', 'essenti', 'comxexxa'])]\n",
            "[WordList(['unntv', 'so', 'scari']), WordList(['so', 'scari', 'how']), WordList(['scari', 'how', 'peopl']), WordList(['how', 'peopl', 'treat']), WordList(['peopl', 'treat', 'anim']), WordList(['treat', 'anim', 'nnthey']), WordList(['anim', 'nnthey', 'burn']), WordList(['nnthey', 'burn', 'pig']), WordList(['burn', 'pig', 'alivennpig']), WordList(['pig', 'alivennpig', 'animalright']), WordList(['alivennpig', 'animalright', 'brutalchina']), WordList(['animalright', 'brutalchina', 'chinesecoronavixexxa'])]\n",
            "[WordList(['nikkimiumiu', 'a', 'hongkong']), WordList(['a', 'hongkong', 'femal']), WordList(['hongkong', 'femal', 'polic']), WordList(['femal', 'polic', 'infect']), WordList(['polic', 'infect', 'wuhancoronaviru']), WordList(['infect', 'wuhancoronaviru', 'reject']), WordList(['wuhancoronaviru', 'reject', 'wear']), WordList(['reject', 'wear', 'mask']), WordList(['wear', 'mask', 'carita']), WordList(['mask', 'carita', 'medic']), WordList(['carita', 'medic', 'centr']), WordList(['medic', 'centr', 'she']), WordList(['centr', 'she', 'cxexxa'])]\n",
            "[WordList(['allmui', 'hkpolic', 'use']), WordList(['hkpolic', 'use', 'ruler']), WordList(['use', 'ruler', 'measur']), WordList(['ruler', 'measur', 'distanc']), WordList(['measur', 'distanc', 'tabl']), WordList(['distanc', 'tabl', 'barnni']), WordList(['tabl', 'barnni', 'think']), WordList(['barnni', 'think', 'hkpolic']), WordList(['think', 'hkpolic', 'workplac']), WordList(['hkpolic', 'workplac', 'restaxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['liberti', 'nufsaid', 'glcarlstrom']), WordList(['nufsaid', 'glcarlstrom', 'china']), WordList(['glcarlstrom', 'china', 'former']), WordList(['china', 'former', 'militari']), WordList(['former', 'militari', 'scientist']), WordList(['militari', 'scientist', 'reveal']), WordList(['scientist', 'reveal', 'nhttpstcowrnbauscynxexxcus']), WordList(['reveal', 'nhttpstcowrnbauscynxexxcus', 'gene']), WordList(['nhttpstcowrnbauscynxexxcus', 'gene', 'edit']), WordList(['gene', 'edit', 'ofxexxa'])]\n",
            "[WordList(['bozraeliavi', 'cant', 'imag']), WordList(['cant', 'imag', 'imagin']), WordList(['imag', 'imagin', 'mani']), WordList(['imagin', 'mani', 'infect']), WordList(['mani', 'infect', 'wuhancoronaviru']), WordList(['infect', 'wuhancoronaviru', 'china']), WordList(['wuhancoronaviru', 'china', 'miss']), WordList(['china', 'miss', 'nnchinaliedpeopledi']), WordList(['miss', 'nnchinaliedpeopledi', 'nmadeinchina'])]\n",
            "[WordList(['brealjameswood', 'what', 'wuhancoronaviru']), WordList(['what', 'wuhancoronaviru', 'quarantin']), WordList(['wuhancoronaviru', 'quarantin', 'look']), WordList(['quarantin', 'look', 'like']), WordList(['look', 'like', 'countri']), WordList(['like', 'countri', 'xfxfxaxaxfxfxxxfxfxaxaxfxfxx'])]\n",
            "[WordList(['realjameswood', 'the', 'other']), WordList(['the', 'other', 'import']), WordList(['other', 'import', 'weapon']), WordList(['import', 'weapon', 'war']), WordList(['weapon', 'war', 'wuhancoronaviru']), WordList(['war', 'wuhancoronaviru', 'httpstcoaybwqdzz'])]\n",
            "[WordList(['bnote', 'globalist', 'flag']), WordList(['globalist', 'flag', 'sit']), WordList(['flag', 'sit', 'who']), WordList(['sit', 'who', 'noth']), WordList(['who', 'noth', 'china']), WordList(['noth', 'china', 'puppet']), WordList(['china', 'puppet', 'nwo']), WordList(['puppet', 'nwo', 'wuhancoronaviru']), WordList(['nwo', 'wuhancoronaviru', 'covid']), WordList(['wuhancoronaviru', 'covid', 'httpstcofymsacknc'])]\n",
            "[WordList(['bhkworldciti', 'who', 'rthknew']), WordList(['who', 'rthknew', 'bruceaylward']), WordList(['rthknew', 'bruceaylward', 'hung']), WordList(['bruceaylward', 'hung', 'ask']), WordList(['hung', 'ask', 'taiwan']), WordList(['ask', 'taiwan', 'interviewnntaiwanisnotchinaxexxa']), WordList(['taiwan', 'interviewnntaiwanisnotchinaxexxa', 'httpstcolnysjhstyi'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['fankungyan', 'locat', 'xexxcshenzhen']), WordList(['locat', 'xexxcshenzhen', 'customsxexxc']), WordList(['xexxcshenzhen', 'customsxexxc', 'unverifiednwuhancoronaviru'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['bdonlemon', 'ani', 'truth']), WordList(['ani', 'truth', 'rumor']), WordList(['truth', 'rumor', 'realdonaldtrump']), WordList(['rumor', 'realdonaldtrump', 'blame']), WordList(['realdonaldtrump', 'blame', 'wutangclan']), WordList(['blame', 'wutangclan', 'viral']), WordList(['wutangclan', 'viral', 'outbreakxexxa']), WordList(['viral', 'outbreakxexxa', 'httpstconvykobcpm'])]\n",
            "[WordList(['bredsteez', 'isnt', 'who']), WordList(['isnt', 'who', 'puppet']), WordList(['who', 'puppet', 'china']), WordList(['puppet', 'china', 'taiwan']), WordList(['china', 'taiwan', 'great']), WordList(['taiwan', 'great', 'job']), WordList(['great', 'job', 'covid']), WordList(['job', 'covid', 'who']), WordList(['covid', 'who', 'doesnt']), WordList(['who', 'doesnt', 'acknowledg']), WordList(['doesnt', 'acknowledg', 'stxexxa']), WordList(['acknowledg', 'stxexxa', 'httpstcoqybdooku'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['bgoa', 'welcom', 'crpfindia']), WordList(['welcom', 'crpfindia', 'nmani']), WordList(['crpfindia', 'nmani', 'peopl']), WordList(['nmani', 'peopl', 'goa']), WordList(['peopl', 'goa', 'seen']), WordList(['goa', 'seen', 'maintain']), WordList(['seen', 'maintain', 'social']), WordList(['maintain', 'social', 'distanc']), WordList(['social', 'distanc', 'shop']), WordList(['distanc', 'shop', 'essentixexxa']), WordList(['shop', 'essentixexxa', 'httpstcoygexwn'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['bcherijacobu', 'realdonaldtrump', 'the']), WordList(['realdonaldtrump', 'the', 'chine']), WordList(['the', 'chine', 'communist']), WordList(['chine', 'communist', 'govern']), WordList(['communist', 'govern', 'mass']), WordList(['govern', 'mass', 'murder']), WordList(['mass', 'murder', 'they']), WordList(['murder', 'they', 'releas']), WordList(['they', 'releas', 'thexexxa']), WordList(['releas', 'thexexxa', 'httpstcoadnmtmnn'])]\n",
            "[WordList(['fankungyan', 'locat', 'xexxcshenzhen']), WordList(['locat', 'xexxcshenzhen', 'customsxexxc']), WordList(['xexxcshenzhen', 'customsxexxc', 'unverifiednwuhancoronaviru'])]\n",
            "[WordList(['therealcook', 'now', 'that']), WordList(['now', 'that', 'immun']), WordList(['that', 'immun', 'systemnnwuhancoronavirusnnyearold']), WordList(['immun', 'systemnnwuhancoronavirusnnyearold', 'italian']), WordList(['systemnnwuhancoronavirusnnyearold', 'italian', 'man']), WordList(['italian', 'man', 'born']), WordList(['man', 'born', 'spanish']), WordList(['born', 'spanish', 'flu']), WordList(['spanish', 'flu', 'pandem']), WordList(['flu', 'pandem', 'surviv']), WordList(['pandem', 'surviv', 'coroxexxa'])]\n",
            "[WordList(['allmui', 'hkpolic', 'use']), WordList(['hkpolic', 'use', 'ruler']), WordList(['use', 'ruler', 'measur']), WordList(['ruler', 'measur', 'distanc']), WordList(['measur', 'distanc', 'tabl']), WordList(['distanc', 'tabl', 'barnni']), WordList(['tabl', 'barnni', 'think']), WordList(['barnni', 'think', 'hkpolic']), WordList(['think', 'hkpolic', 'workplac']), WordList(['hkpolic', 'workplac', 'restaxexxa'])]\n",
            "[WordList(['joydeepghosh', 'universityofhyderabad', 'faculti']), WordList(['universityofhyderabad', 'faculti', 'develop']), WordList(['faculti', 'develop', 'potenti']), WordList(['develop', 'potenti', 'vaccin']), WordList(['potenti', 'vaccin', 'candid']), WordList(['vaccin', 'candid', 'against']), WordList(['candid', 'against', 'coronaviru']), WordList(['against', 'coronaviru', 'hope']), WordList(['coronaviru', 'hope', 'bring']), WordList(['hope', 'bring', 'lightxexxa'])]\n",
            "[WordList(['imshinbei', 'hong', 'kong']), WordList(['hong', 'kong', 'karat']), WordList(['kong', 'karat', 'team']), WordList(['karat', 'team', 'member']), WordList(['team', 'member', 'lee']), WordList(['member', 'lee', 'chunho']), WordList(['lee', 'chunho', 'confirm']), WordList(['chunho', 'confirm', 'wuhancoronaviru']), WordList(['confirm', 'wuhancoronaviru', 'said']), WordList(['wuhancoronaviru', 'said', 'high']), WordList(['said', 'high', 'fever']), WordList(['high', 'fever', 'made']), WordList(['fever', 'made', 'previou']), WordList(['made', 'previou', 'effxexxa'])]\n",
            "[WordList(['nikkimiumiu', 'a', 'hongkong']), WordList(['a', 'hongkong', 'femal']), WordList(['hongkong', 'femal', 'polic']), WordList(['femal', 'polic', 'infect']), WordList(['polic', 'infect', 'wuhancoronaviru']), WordList(['infect', 'wuhancoronaviru', 'reject']), WordList(['wuhancoronaviru', 'reject', 'wear']), WordList(['reject', 'wear', 'mask']), WordList(['wear', 'mask', 'carita']), WordList(['mask', 'carita', 'medic']), WordList(['carita', 'medic', 'centr']), WordList(['medic', 'centr', 'she']), WordList(['centr', 'she', 'cxexxa'])]\n",
            "[WordList(['janedryden', 'are', 'victim']), WordList(['are', 'victim', 'hate']), WordList(['victim', 'hate', 'crime']), WordList(['hate', 'crime', 'wuhancoronaviru']), WordList(['crime', 'wuhancoronaviru', 'chinesecoronaviru']), WordList(['wuhancoronaviru', 'chinesecoronaviru', 'we']), WordList(['chinesecoronaviru', 'we', 'shouldnt']), WordList(['we', 'shouldnt', 'blame']), WordList(['shouldnt', 'blame', 'random']), WordList(['blame', 'random', 'chine']), WordList(['random', 'chine', 'peoxexxa'])]\n",
            "[WordList(['solomonyu', 'did', 'chine']), WordList(['did', 'chine', 'mobil']), WordList(['chine', 'mobil', 'carrier']), WordList(['mobil', 'carrier', 'show']), WordList(['carrier', 'show', 'increas']), WordList(['show', 'increas', 'user']), WordList(['increas', 'user', 'if']), WordList(['user', 'if', 'not']), WordList(['if', 'not', 'scenario']), WordList(['not', 'scenario', 'pay']), WordList(['scenario', 'pay', 'cell']), WordList(['pay', 'cell', 'phone']), WordList(['cell', 'phone', 'billsxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['hoccgoomus', 'first', 'u']), WordList(['first', 'u', 'italyxfxfxx']), WordList(['u', 'italyxfxfxx', 'the']), WordList(['italyxfxfxx', 'the', 'tri']), WordList(['the', 'tri', 'put']), WordList(['tri', 'put', 'blame']), WordList(['put', 'blame', 'countri']), WordList(['blame', 'countri', 'faster']), WordList(['countri', 'faster', 'truth']), WordList(['faster', 'truth', 'spreadnnthi']), WordList(['truth', 'spreadnnthi', 'propxexxa'])]\n",
            "[WordList(['rollypoli', 'stevescalis', 'nanc']), WordList(['stevescalis', 'nanc', 'wast']), WordList(['nanc', 'wast', 'dec']), WordList(['wast', 'dec', 'feb']), WordList(['dec', 'feb', 'th']), WordList(['feb', 'th', 'shampeach']), WordList(['th', 'shampeach', 'instead']), WordList(['shampeach', 'instead', 'prepar']), WordList(['instead', 'prepar', 'wuhancoronaviru'])]\n",
            "[WordList(['hwyoungg', 'wilfredchan', 'bearmui']), WordList(['wilfredchan', 'bearmui', 'taiwan']), WordList(['bearmui', 'taiwan', 'avoid']), WordList(['taiwan', 'avoid', 'first']), WordList(['avoid', 'first', 'round']), WordList(['first', 'round', 'wuhancoronaviru']), WordList(['round', 'wuhancoronaviru', 'outbreak']), WordList(['wuhancoronaviru', 'outbreak', 'earli']), WordList(['outbreak', 'earli', 'action']), WordList(['earli', 'action', 'rather']), WordList(['action', 'rather', 'ccpxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['aniilai', 'no', 'privileg']), WordList(['no', 'privileg', 'who']), WordList(['privileg', 'who', 'would']), WordList(['who', 'would', 'believ']), WordList(['would', 'believ', 'silli']), WordList(['believ', 'silli', 'wordsnboth']), WordList(['silli', 'wordsnboth', 'hkgov']), WordList(['wordsnboth', 'hkgov', 'fehd']), WordList(['hkgov', 'fehd', 'amp']), WordList(['fehd', 'amp', 'hkpoliceterrorist']), WordList(['amp', 'hkpoliceterrorist', 'whi']), WordList(['hkpoliceterrorist', 'whi', 'diff']), WordList(['whi', 'diff', 'presentationnfxexxa'])]\n",
            "[WordList(['peopleschamp', 'plot', 'twist']), WordList(['plot', 'twist', 'the']), WordList(['twist', 'the', 'real']), WordList(['the', 'real', 'racist']), WordList(['real', 'racist', 'medium']), WordList(['racist', 'medium', 'outlet']), WordList(['medium', 'outlet', 'quickli']), WordList(['outlet', 'quickli', 'jump']), WordList(['quickli', 'jump', 'call']), WordList(['jump', 'call', 'everyth']), WordList(['call', 'everyth', 'racistnnchineseviru']), WordList(['everyth', 'racistnnchineseviru', 'chinesewxexxa'])]\n",
            "[WordList(['britishk', 'ezracheungtoto', 'who']), WordList(['ezracheungtoto', 'who', 'doe']), WordList(['who', 'doe', 'who']), WordList(['doe', 'who', 'stand']), WordList(['who', 'stand', 'wuhanhealthorganis']), WordList(['stand', 'wuhanhealthorganis', 'what']), WordList(['wuhanhealthorganis', 'what', 'differ']), WordList(['what', 'differ', 'bruce']), WordList(['differ', 'bruce', 'aylward']), WordList(['bruce', 'aylward', 'amp']), WordList(['aylward', 'amp', 'drtedro']), WordList(['amp', 'drtedro', 'seexexxa'])]\n",
            "[WordList(['benlukkk', 'anderscorr', 'if']), WordList(['anderscorr', 'if', 'itali']), WordList(['if', 'itali', 'didnxexxt']), WordList(['itali', 'didnxexxt', 'permit']), WordList(['didnxexxt', 'permit', 'chine']), WordList(['permit', 'chine', 'citizen']), WordList(['chine', 'citizen', 'go']), WordList(['citizen', 'go', 'begin']), WordList(['go', 'begin', 'chineseviru']), WordList(['begin', 'chineseviru', 'go']), WordList(['chineseviru', 'go', 'xfxfxxaexfxfxxb']), WordList(['go', 'xfxfxxaexfxfxxb', 'wuhanxexxa'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['bare', 'victim', 'hate']), WordList(['victim', 'hate', 'crime']), WordList(['hate', 'crime', 'wuhancoronaviru']), WordList(['crime', 'wuhancoronaviru', 'chinesecoronaviru']), WordList(['wuhancoronaviru', 'chinesecoronaviru', 'we']), WordList(['chinesecoronaviru', 'we', 'shouldnt']), WordList(['we', 'shouldnt', 'blame']), WordList(['shouldnt', 'blame', 'random']), WordList(['blame', 'random', 'chinxexxa']), WordList(['random', 'chinxexxa', 'httpstcovhtujclqxn'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['drmartyfox', 'just', 'like']), WordList(['just', 'like', 'they']), WordList(['like', 'they', 'suddenli']), WordList(['they', 'suddenli', 'find']), WordList(['suddenli', 'find', 'elect']), WordList(['find', 'elect', 'ballotsnnth']), WordList(['elect', 'ballotsnnth', 'democrat']), WordList(['ballotsnnth', 'democrat', 'mob']), WordList(['democrat', 'mob', 'aka']), WordList(['mob', 'aka', 'the']), WordList(['aka', 'the', 'seiu']), WordList(['the', 'seiu', 'union']), WordList(['seiu', 'union', 'suddenli']), WordList(['union', 'suddenli', 'find']), WordList(['suddenli', 'find', 'mysteri']), WordList(['find', 'mysteri', 'stash']), WordList(['mysteri', 'stash', 'of']), WordList(['stash', 'of', 'mixexxa'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['bnufsaid', 'glcarlstrom', 'china']), WordList(['glcarlstrom', 'china', 'former']), WordList(['china', 'former', 'militari']), WordList(['former', 'militari', 'scientist']), WordList(['militari', 'scientist', 'reveal']), WordList(['scientist', 'reveal', 'nhttpstcowrnbauscynxexxcus']), WordList(['reveal', 'nhttpstcowrnbauscynxexxcus', 'gene']), WordList(['nhttpstcowrnbauscynxexxcus', 'gene', 'editxexxa']), WordList(['gene', 'editxexxa', 'httpstcoqgtepvsaog'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['t', 'joydeepghosh', 'universityofhyderabad']), WordList(['joydeepghosh', 'universityofhyderabad', 'faculti']), WordList(['universityofhyderabad', 'faculti', 'develop']), WordList(['faculti', 'develop', 'potenti']), WordList(['develop', 'potenti', 'vaccin']), WordList(['potenti', 'vaccin', 'candid']), WordList(['vaccin', 'candid', 'against']), WordList(['candid', 'against', 'coronaviru'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['bthi', 'wonxexxt', 'forgotten']), WordList(['wonxexxt', 'forgotten', 'end']), WordList(['forgotten', 'end', 'day']), WordList(['end', 'day', 'bill']), WordList(['day', 'bill', 'come']), WordList(['bill', 'come', 'who']), WordList(['come', 'who', 'wholiedpeopledi']), WordList(['who', 'wholiedpeopledi', 'wuhanvirusxexxa']), WordList(['wholiedpeopledi', 'wuhanvirusxexxa', 'httpstcocxagccfab'])]\n",
            "[WordList(['britishk', 'hkworldciti', 'who']), WordList(['hkworldciti', 'who', 'rthknew']), WordList(['who', 'rthknew', 'doe']), WordList(['rthknew', 'doe', 'fear']), WordList(['doe', 'fear', 'applaud']), WordList(['fear', 'applaud', 'taiwan']), WordList(['applaud', 'taiwan', 'success']), WordList(['taiwan', 'success', 'combat']), WordList(['success', 'combat', 'wuhancoronaviru']), WordList(['combat', 'wuhancoronaviru', 'we']), WordList(['wuhancoronaviru', 'we', 'noxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['buniversityofhyderabad', 'faculti', 'develop']), WordList(['faculti', 'develop', 'potenti']), WordList(['develop', 'potenti', 'vaccin']), WordList(['potenti', 'vaccin', 'candid']), WordList(['vaccin', 'candid', 'against']), WordList(['candid', 'against', 'coronaviru']), WordList(['against', 'coronaviru', 'hope']), WordList(['coronaviru', 'hope', 'bringsxexxa']), WordList(['hope', 'bringsxexxa', 'httpstcoajapkymvk'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['bgten', 'prasenj', 'ask']), WordList(['prasenj', 'ask', 'question']), WordList(['ask', 'question', 'wuhancoronaviru']), WordList(['question', 'wuhancoronaviru', 'chinaviru']), WordList(['wuhancoronaviru', 'chinaviru', 'covid']), WordList(['chinaviru', 'covid', 'architect']), WordList(['covid', 'architect', 'ccp']), WordList(['architect', 'ccp', 'propaganda']), WordList(['ccp', 'propaganda', 'war']), WordList(['propaganda', 'war', 'spokxexxa'])]\n",
            "[WordList(['cherri', 'nytim', 'ccp']), WordList(['nytim', 'ccp', 'amp']), WordList(['ccp', 'amp', 'russia']), WordList(['amp', 'russia', 'twist']), WordList(['russia', 'twist', 'fact']), WordList(['twist', 'fact', 'tri']), WordList(['fact', 'tri', 'best']), WordList(['tri', 'best', 'brainwash']), WordList(['best', 'brainwash', 'peopl']), WordList(['brainwash', 'peopl', 'pretend']), WordList(['peopl', 'pretend', 'victim']), WordList(['pretend', 'victim', 'wuhancoxexxa'])]\n",
            "[WordList(['therealcook', 'now', 'that']), WordList(['now', 'that', 'immun']), WordList(['that', 'immun', 'systemnnwuhancoronavirusnnyearold']), WordList(['immun', 'systemnnwuhancoronavirusnnyearold', 'italian']), WordList(['systemnnwuhancoronavirusnnyearold', 'italian', 'man']), WordList(['italian', 'man', 'born']), WordList(['man', 'born', 'spanish']), WordList(['born', 'spanish', 'flu']), WordList(['spanish', 'flu', 'pandem']), WordList(['flu', 'pandem', 'surviv']), WordList(['pandem', 'surviv', 'coroxexxa'])]\n",
            "[WordList(['bwbyeat', 'who', 'taiwan']), WordList(['who', 'taiwan', 'amp']), WordList(['taiwan', 'amp', 'ppl']), WordList(['amp', 'ppl', 'dont']), WordList(['ppl', 'dont', 'need']), WordList(['dont', 'need', 'who']), WordList(['need', 'who', 'public']), WordList(['who', 'public', 'health']), WordList(['public', 'health', 'advic']), WordList(['health', 'advic', 'anywaynhttpstcoibuxndntxexxa']), WordList(['advic', 'anywaynhttpstcoibuxndntxexxa', 'httpstcoisuxrbghwr'])]\n",
            "[WordList(['bbsrbuzz', 'the', 'entir']), WordList(['the', 'entir', 'campu']), WordList(['entir', 'campu', 'driem']), WordList(['campu', 'driem', 'includ']), WordList(['driem', 'includ', 'four']), WordList(['includ', 'four', 'boy']), WordList(['four', 'boy', 'hostel']), WordList(['boy', 'hostel', 'room']), WordList(['hostel', 'room', 'girl']), WordList(['room', 'girl', 'hostel']), WordList(['girl', 'hostel', 'room']), WordList(['hostel', 'room', 'academ']), WordList(['room', 'academ', 'blocksxexxa'])]\n",
            "[WordList(['aniilai', 'no', 'privileg']), WordList(['no', 'privileg', 'who']), WordList(['privileg', 'who', 'would']), WordList(['who', 'would', 'believ']), WordList(['would', 'believ', 'silli']), WordList(['believ', 'silli', 'wordsnboth']), WordList(['silli', 'wordsnboth', 'hkgov']), WordList(['wordsnboth', 'hkgov', 'fehd']), WordList(['hkgov', 'fehd', 'amp']), WordList(['fehd', 'amp', 'hkpoliceterrorist']), WordList(['amp', 'hkpoliceterrorist', 'whi']), WordList(['hkpoliceterrorist', 'whi', 'diff']), WordList(['whi', 'diff', 'presentationnfxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['pennyrelgit', 'repgallagh', 'noth']), WordList(['repgallagh', 'noth', 'chang']), WordList(['noth', 'chang', 'fact']), WordList(['chang', 'fact', 'wuhancoronaviru']), WordList(['fact', 'wuhancoronaviru', 'come']), WordList(['wuhancoronaviru', 'come', 'chinazi']), WordList(['come', 'chinazi', 'httpstcomctltwdg'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['zoechanhongkong', 'in', 'interview']), WordList(['in', 'interview', 'rthk']), WordList(['interview', 'rthk', 'bruce']), WordList(['rthk', 'bruce', 'alyward']), WordList(['bruce', 'alyward', 'who']), WordList(['alyward', 'who', 'ask']), WordList(['who', 'ask', 'reconsid']), WordList(['ask', 'reconsid', 'taiwanxexx']), WordList(['reconsid', 'taiwanxexx', 'membership']), WordList(['taiwanxexx', 'membership', 'given']), WordList(['membership', 'given', 'good']), WordList(['given', 'good', 'perforxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['bprasenj', 'ask', 'question']), WordList(['ask', 'question', 'wuhancoronaviru']), WordList(['question', 'wuhancoronaviru', 'chinaviru']), WordList(['wuhancoronaviru', 'chinaviru', 'covid']), WordList(['chinaviru', 'covid', 'architect']), WordList(['covid', 'architect', 'ccp']), WordList(['architect', 'ccp', 'propagandaxexxa']), WordList(['ccp', 'propagandaxexxa', 'httpstcooknagkzkjt'])]\n",
            "[WordList(['bactual', 'democrat', 'practic']), WordList(['democrat', 'practic', 'social']), WordList(['practic', 'social', 'distanc']), WordList(['social', 'distanc', 'move']), WordList(['distanc', 'move', 'canada']), WordList(['move', 'canada', 'wuhancoronaviru'])]\n",
            "[WordList(['allmui', 'hkpolic', 'use']), WordList(['hkpolic', 'use', 'ruler']), WordList(['use', 'ruler', 'measur']), WordList(['ruler', 'measur', 'distanc']), WordList(['measur', 'distanc', 'tabl']), WordList(['distanc', 'tabl', 'barnni']), WordList(['tabl', 'barnni', 'think']), WordList(['barnni', 'think', 'hkpolic']), WordList(['think', 'hkpolic', 'workplac']), WordList(['hkpolic', 'workplac', 'restaxexxa'])]\n",
            "[WordList(['bthi', 'hospit', 'seriou']), WordList(['hospit', 'seriou', 'manag']), WordList(['seriou', 'manag', 'problem']), WordList(['manag', 'problem', 'if']), WordList(['problem', 'if', 'doctor']), WordList(['if', 'doctor', 'said']), WordList(['doctor', 'said', 'true']), WordList(['said', 'true', 'disclos']), WordList(['true', 'disclos', 'info']), WordList(['disclos', 'info', 'thxexxa']), WordList(['info', 'thxexxa', 'httpstcorujafbq'])]\n",
            "[WordList(['bandrew', 'cuomo', 'practic']), WordList(['cuomo', 'practic', 'social']), WordList(['practic', 'social', 'distanc']), WordList(['social', 'distanc', 'move']), WordList(['distanc', 'move', 'canada']), WordList(['move', 'canada', 'wuhancoronaviru'])]\n",
            "[WordList(['teresaw', 'senrickscott', 'the']), WordList(['senrickscott', 'the', 'wuhancoronaviru']), WordList(['the', 'wuhancoronaviru', 'alarm']), WordList(['wuhancoronaviru', 'alarm', 'world']), WordList(['alarm', 'world', 'china']), WordList(['world', 'china', 'unreli']), WordList(['china', 'unreli', 'danger']), WordList(['unreli', 'danger', 'the']), WordList(['danger', 'the', 'world']), WordList(['the', 'world', 'mustxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['trumpwarroom', 'timelin', 'the']), WordList(['timelin', 'the', 'trump']), WordList(['the', 'trump', 'administr']), WordList(['trump', 'administr', 'decis']), WordList(['administr', 'decis', 'action']), WordList(['decis', 'action', 'combat']), WordList(['action', 'combat', 'coronaviru']), WordList(['combat', 'coronaviru', 'gtnhttpstcofnwkeujbb']), WordList(['coronaviru', 'gtnhttpstcofnwkeujbb', 'nnchinesevixexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['bjust', 'imagin', 'world']), WordList(['imagin', 'world', 'without']), WordList(['world', 'without', 'china']), WordList(['without', 'china', 'le']), WordList(['china', 'le', 'global']), WordList(['le', 'global', 'warm']), WordList(['global', 'warm', 'a']), WordList(['warm', 'a', 'bit']), WordList(['a', 'bit', 'expens']), WordList(['bit', 'expens', 'still']), WordList(['expens', 'still', 'better']), WordList(['still', 'better', 'air']), WordList(['better', 'air', 'benefit']), WordList(['air', 'benefit', 'motxexxa']), WordList(['benefit', 'motxexxa', 'httpstcodhsbopoow'])]\n",
            "[WordList(['bimrankhanpti', 'clarencehous', 'borisjohnson']), WordList(['clarencehous', 'borisjohnson', 'the']), WordList(['borisjohnson', 'the', 'blame']), WordList(['the', 'blame', 'lie']), WordList(['blame', 'lie', 'china']), WordList(['lie', 'china', 'theyr']), WordList(['china', 'theyr', 'respons']), WordList(['theyr', 'respons', 'death']), WordList(['respons', 'death', 'arouxexxa']), WordList(['death', 'arouxexxa', 'httpstcodltdkzv'])]\n",
            "[WordList(['alantonelson', 'tracyjan', 'nation']), WordList(['tracyjan', 'nation', 'univers']), WordList(['nation', 'univers', 'healthcar']), WordList(['univers', 'healthcar', 'wouldv']), WordList(['healthcar', 'wouldv', 'better']), WordList(['wouldv', 'better', 'prepar']), WordList(['better', 'prepar', 'u']), WordList(['prepar', 'u', 'deal']), WordList(['u', 'deal', 'ccpviru']), WordList(['deal', 'ccpviru', 'serious']), WordList(['ccpviru', 'serious', 'like']), WordList(['serious', 'like', 'ixexxa'])]\n",
            "[WordList(['lawmic', 'nathanlawkc', 'thecantonesegod']), WordList(['nathanlawkc', 'thecantonesegod', 'scrap']), WordList(['thecantonesegod', 'scrap', 'who']), WordList(['scrap', 'who', 'rebrand']), WordList(['who', 'rebrand', 'cho']), WordList(['rebrand', 'cho', 'china']), WordList(['cho', 'china', 'health']), WordList(['china', 'health', 'organ']), WordList(['health', 'organ', 'now']), WordList(['organ', 'now', 'mission']), WordList(['now', 'mission', 'make']), WordList(['mission', 'make', 'wixexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['trumpwarroom', 'timelin', 'the']), WordList(['timelin', 'the', 'trump']), WordList(['the', 'trump', 'administr']), WordList(['trump', 'administr', 'decis']), WordList(['administr', 'decis', 'action']), WordList(['decis', 'action', 'combat']), WordList(['action', 'combat', 'coronaviru']), WordList(['combat', 'coronaviru', 'gtnhttpstcofnwkeujbb']), WordList(['coronaviru', 'gtnhttpstcofnwkeujbb', 'nnchinesevixexxa'])]\n",
            "[WordList(['bpeopl', 'scare', 'liberti']), WordList(['scare', 'liberti', 'dissolv']), WordList(['liberti', 'dissolv', 'marklevinshow']), WordList(['dissolv', 'marklevinshow', 'aptli']), WordList(['marklevinshow', 'aptli', 'put']), WordList(['aptli', 'put', 'wuhanviru']), WordList(['put', 'wuhanviru', 'wuhancoronaviru'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['bmisguid', 'drug', 'advic']), WordList(['drug', 'advic', 'covid']), WordList(['advic', 'covid', 'ibuprofen']), WordList(['covid', 'ibuprofen', 'nsaid']), WordList(['ibuprofen', 'nsaid', 'intervent']), WordList(['nsaid', 'intervent', 'wuhancoronaviru']), WordList(['intervent', 'wuhancoronaviru', 'outbreak']), WordList(['wuhancoronaviru', 'outbreak', 'clusterxexxa']), WordList(['outbreak', 'clusterxexxa', 'httpstcojviwvkxr'])]\n",
            "[WordList(['rajeevsrinivasa', 'karnataka', 'enforc']), WordList(['karnataka', 'enforc', 'cordonsanitair']), WordList(['enforc', 'cordonsanitair', 'around']), WordList(['cordonsanitair', 'around', 'wuhancoronaviru']), WordList(['around', 'wuhancoronaviru', 'hit']), WordList(['wuhancoronaviru', 'hit', 'kasaragod']), WordList(['hit', 'kasaragod', 'klnnkejriw']), WordList(['kasaragod', 'klnnkejriw', 'broke']), WordList(['klnnkejriw', 'broke', 'cordxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['lawmic', 'nathanlawkc', 'thecantonesegod']), WordList(['nathanlawkc', 'thecantonesegod', 'scrap']), WordList(['thecantonesegod', 'scrap', 'who']), WordList(['scrap', 'who', 'rebrand']), WordList(['who', 'rebrand', 'cho']), WordList(['rebrand', 'cho', 'china']), WordList(['cho', 'china', 'health']), WordList(['china', 'health', 'organ']), WordList(['health', 'organ', 'now']), WordList(['organ', 'now', 'mission']), WordList(['now', 'mission', 'make']), WordList(['mission', 'make', 'wixexxa'])]\n",
            "[WordList(['bevid', 'china', 'sponsor']), WordList(['china', 'sponsor', 'china']), WordList(['sponsor', 'china', 'must']), WordList(['china', 'must', 'held']), WordList(['must', 'held', 'account']), WordList(['held', 'account', 'spread']), WordList(['account', 'spread', 'coronaviru']), WordList(['spread', 'coronaviru', 'videoxexxa']), WordList(['coronaviru', 'videoxexxa', 'httpstcomjkuydtzpf'])]\n",
            "[WordList(['roofmonqey', 'ahhh', 'hey']), WordList(['ahhh', 'hey', 'china']), WordList(['hey', 'china', 'death']), WordList(['china', 'death', 'toll']), WordList(['death', 'toll', 'wuhancoronaviru']), WordList(['toll', 'wuhancoronaviru', 'xfxfxxnnwwgwga'])]\n",
            "[WordList(['mymonke', 'chinaliedpeopledi', 'nnaround']), WordList(['chinaliedpeopledi', 'nnaround', 'day']), WordList(['nnaround', 'day', 'ago']), WordList(['day', 'ago', 'basic']), WordList(['ago', 'basic', 'everi']), WordList(['basic', 'everi', 'day']), WordList(['everi', 'day', 'two']), WordList(['day', 'two', 'peopl']), WordList(['two', 'peopl', 'jump']), WordList(['peopl', 'jump', 'buildingsxexxdnnsixexxa'])]\n",
            "[WordList(['therealcook', 'now', 'that']), WordList(['now', 'that', 'immun']), WordList(['that', 'immun', 'systemnnwuhancoronavirusnnyearold']), WordList(['immun', 'systemnnwuhancoronavirusnnyearold', 'italian']), WordList(['systemnnwuhancoronavirusnnyearold', 'italian', 'man']), WordList(['italian', 'man', 'born']), WordList(['man', 'born', 'spanish']), WordList(['born', 'spanish', 'flu']), WordList(['spanish', 'flu', 'pandem']), WordList(['flu', 'pandem', 'surviv']), WordList(['pandem', 'surviv', 'coroxexxa'])]\n",
            "[WordList(['hyltonrobin', 'xfxfxaxa', 'break']), WordList(['xfxfxaxa', 'break', 'fox']), WordList(['break', 'fox', 'busi']), WordList(['fox', 'busi', 'network']), WordList(['busi', 'network', 'fire']), WordList(['network', 'fire', 'trish']), WordList(['fire', 'trish', 'regan']), WordList(['trish', 'regan', 'tell']), WordList(['regan', 'tell', 'truth']), WordList(['tell', 'truth', 'about']), WordList(['truth', 'about', 'how']), WordList(['about', 'how', 'liber']), WordList(['how', 'liber', 'medium']), WordList(['liber', 'medium', 'wa']), WordList(['medium', 'wa', 'use']), WordList(['wa', 'use', 'wuhancoronavirxexxa'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n98YZnQo70j1",
        "colab_type": "code",
        "outputId": "48f5bfe8-c225-4bb5-dcbb-329c296fe0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# (2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "import nltk\n",
        "\n",
        "bigrams_lst=[]\n",
        "tokens_lst=[]\n",
        "for i in range(len(data[\"tweet_data\"])):\n",
        " nltk_tokens = nltk.word_tokenize(data[\"tweet_data\"][i])  \n",
        " tokens_lst= tokens_lst+(nltk_tokens)\n",
        " bigrams_lst=bigrams_lst+(list(nltk.bigrams(nltk_tokens)))\n",
        "bigrams_dict={}\n",
        "for  i in range(len(bigrams_lst)):\n",
        "    bigrams_dict[bigrams_lst[i]]=bigrams_lst.count(bigrams_lst[i])/tokens_lst.count(bigrams_lst[i][1])\n",
        "print(bigrams_dict)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('rajeevsrinivasa', 'karnataka'): 1.0, ('karnataka', 'enforc'): 1.0, ('enforc', 'cordonsanitair'): 1.0, ('cordonsanitair', 'around'): 1.0, ('around', 'wuhancoronaviru'): 0.28125, ('wuhancoronaviru', 'hit'): 1.0, ('hit', 'kasaragod'): 1.0, ('kasaragod', 'klnnkejriw'): 1.0, ('klnnkejriw', 'broke'): 1.0, ('broke', 'cordxexxa'): 1.0, ('nikkimiumiu', 'a'): 0.75, ('a', 'hongkong'): 1.0, ('hongkong', 'femal'): 1.0, ('femal', 'polic'): 1.0, ('polic', 'infect'): 0.75, ('infect', 'wuhancoronaviru'): 0.125, ('wuhancoronaviru', 'reject'): 1.0, ('reject', 'wear'): 1.0, ('wear', 'mask'): 1.0, ('mask', 'carita'): 1.0, ('carita', 'medic'): 1.0, ('medic', 'centr'): 1.0, ('centr', 'she'): 1.0, ('she', 'cxexxa'): 1.0, ('allmui', 'hkpolic'): 0.5, ('hkpolic', 'use'): 0.23529411764705882, ('use', 'ruler'): 1.0, ('ruler', 'measur'): 1.0, ('measur', 'distanc'): 0.5, ('distanc', 'tabl'): 1.0, ('tabl', 'barnni'): 1.0, ('barnni', 'think'): 1.0, ('think', 'hkpolic'): 0.5, ('hkpolic', 'workplac'): 1.0, ('workplac', 'restaxexxa'): 1.0, ('mymonke', 'chinaliedpeopledi'): 1.0, ('chinaliedpeopledi', 'nnaround'): 1.0, ('nnaround', 'day'): 0.48, ('day', 'ago'): 1.0, ('ago', 'basic'): 1.0, ('basic', 'everi'): 1.0, ('everi', 'day'): 0.48, ('day', 'two'): 1.0, ('two', 'peopl'): 0.75, ('peopl', 'jump'): 0.9230769230769231, ('jump', 'buildingsxexxdnnsixexxa'): 1.0, ('imshinbei', 'hong'): 1.0, ('hong', 'kong'): 1.0, ('kong', 'karat'): 1.0, ('karat', 'team'): 1.0, ('team', 'member'): 1.0, ('member', 'lee'): 1.0, ('lee', 'chunho'): 1.0, ('chunho', 'confirm'): 1.0, ('confirm', 'wuhancoronaviru'): 0.0625, ('wuhancoronaviru', 'said'): 0.6666666666666666, ('said', 'high'): 1.0, ('high', 'fever'): 1.0, ('fever', 'made'): 1.0, ('made', 'previou'): 1.0, ('previou', 'effxexxa'): 1.0, ('akshpuranik', 'goa'): 0.3333333333333333, ('goa', 'welcom'): 0.5, ('welcom', 'crpfindia'): 1.0, ('crpfindia', 'nmani'): 1.0, ('nmani', 'peopl'): 0.125, ('peopl', 'goa'): 0.6666666666666666, ('goa', 'seen'): 1.0, ('seen', 'maintain'): 1.0, ('maintain', 'social'): 0.5, ('social', 'distanc'): 0.5, ('distanc', 'shop'): 1.0, ('shop', 'essenti'): 1.0, ('essenti', 'comxexxa'): 1.0, ('unntv', 'so'): 1.0, ('so', 'scari'): 1.0, ('scari', 'how'): 0.07142857142857142, ('how', 'peopl'): 0.0625, ('peopl', 'treat'): 1.0, ('treat', 'anim'): 1.0, ('anim', 'nnthey'): 1.0, ('nnthey', 'burn'): 1.0, ('burn', 'pig'): 1.0, ('pig', 'alivennpig'): 1.0, ('alivennpig', 'animalright'): 1.0, ('animalright', 'brutalchina'): 1.0, ('brutalchina', 'chinesecoronavixexxa'): 1.0, ('hyltonrobin', 'xfxfxaxa'): 1.0, ('xfxfxaxa', 'break'): 1.0, ('break', 'fox'): 1.0, ('fox', 'busi'): 1.0, ('busi', 'network'): 1.0, ('network', 'fire'): 1.0, ('fire', 'trish'): 1.0, ('trish', 'regan'): 1.0, ('regan', 'tell'): 1.0, ('tell', 'truth'): 0.8666666666666667, ('truth', 'about'): 1.0, ('about', 'how'): 0.9285714285714286, ('how', 'liber'): 1.0, ('liber', 'medium'): 0.9285714285714286, ('medium', 'wa'): 1.0, ('wa', 'use'): 0.7647058823529411, ('use', 'wuhancoronavirxexxa'): 1.0, ('liberti', 'nufsaid'): 1.0, ('nufsaid', 'glcarlstrom'): 0.5, ('glcarlstrom', 'china'): 0.15384615384615385, ('china', 'former'): 1.0, ('former', 'militari'): 1.0, ('militari', 'scientist'): 1.0, ('scientist', 'reveal'): 1.0, ('reveal', 'nhttpstcowrnbauscynxexxcus'): 1.0, ('nhttpstcowrnbauscynxexxcus', 'gene'): 1.0, ('gene', 'edit'): 1.0, ('edit', 'ofxexxa'): 1.0, ('bozraeliavi', 'cant'): 1.0, ('cant', 'imag'): 1.0, ('imag', 'imagin'): 0.5, ('imagin', 'mani'): 1.0, ('mani', 'infect'): 0.25, ('wuhancoronaviru', 'china'): 0.07692307692307693, ('china', 'miss'): 1.0, ('miss', 'nnchinaliedpeopledi'): 1.0, ('nnchinaliedpeopledi', 'nmadeinchina'): 1.0, ('brealjameswood', 'what'): 0.5, ('what', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'quarantin'): 1.0, ('quarantin', 'look'): 1.0, ('look', 'like'): 0.3333333333333333, ('like', 'countri'): 0.5, ('countri', 'xfxfxaxaxfxfxxxfxfxaxaxfxfxx'): 1.0, ('realjameswood', 'the'): 0.09090909090909091, ('the', 'other'): 1.0, ('other', 'import'): 1.0, ('import', 'weapon'): 1.0, ('weapon', 'war'): 0.5, ('war', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'httpstcoaybwqdzz'): 1.0, ('bnote', 'globalist'): 1.0, ('globalist', 'flag'): 1.0, ('flag', 'sit'): 1.0, ('sit', 'who'): 0.06666666666666667, ('who', 'noth'): 0.5, ('noth', 'china'): 0.07692307692307693, ('china', 'puppet'): 0.5, ('puppet', 'nwo'): 1.0, ('nwo', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'covid'): 0.2, ('covid', 'httpstcofymsacknc'): 1.0, ('bhkworldciti', 'who'): 0.06666666666666667, ('who', 'rthknew'): 1.0, ('rthknew', 'bruceaylward'): 1.0, ('bruceaylward', 'hung'): 1.0, ('hung', 'ask'): 0.25, ('ask', 'taiwan'): 0.2, ('taiwan', 'interviewnntaiwanisnotchinaxexxa'): 1.0, ('interviewnntaiwanisnotchinaxexxa', 'httpstcolnysjhstyi'): 1.0, ('fankungyan', 'locat'): 1.0, ('locat', 'xexxcshenzhen'): 1.0, ('xexxcshenzhen', 'customsxexxc'): 1.0, ('customsxexxc', 'unverifiednwuhancoronaviru'): 1.0, ('bdonlemon', 'ani'): 1.0, ('ani', 'truth'): 0.06666666666666667, ('truth', 'rumor'): 1.0, ('rumor', 'realdonaldtrump'): 0.5, ('realdonaldtrump', 'blame'): 0.2, ('blame', 'wutangclan'): 1.0, ('wutangclan', 'viral'): 1.0, ('viral', 'outbreakxexxa'): 1.0, ('outbreakxexxa', 'httpstconvykobcpm'): 1.0, ('bredsteez', 'isnt'): 1.0, ('isnt', 'who'): 0.06666666666666667, ('who', 'puppet'): 0.5, ('puppet', 'china'): 0.07692307692307693, ('china', 'taiwan'): 0.2, ('taiwan', 'great'): 1.0, ('great', 'job'): 1.0, ('job', 'covid'): 0.2, ('covid', 'who'): 0.06666666666666667, ('who', 'doesnt'): 1.0, ('doesnt', 'acknowledg'): 1.0, ('acknowledg', 'stxexxa'): 1.0, ('stxexxa', 'httpstcoqybdooku'): 1.0, ('bgoa', 'welcom'): 0.5, ('shop', 'essentixexxa'): 1.0, ('essentixexxa', 'httpstcoygexwn'): 1.0, ('bcherijacobu', 'realdonaldtrump'): 0.5, ('realdonaldtrump', 'the'): 0.09090909090909091, ('the', 'chine'): 0.25, ('chine', 'communist'): 1.0, ('communist', 'govern'): 1.0, ('govern', 'mass'): 1.0, ('mass', 'murder'): 1.0, ('murder', 'they'): 0.5, ('they', 'releas'): 1.0, ('releas', 'thexexxa'): 1.0, ('thexexxa', 'httpstcoadnmtmnn'): 1.0, ('therealcook', 'now'): 0.6, ('now', 'that'): 1.0, ('that', 'immun'): 1.0, ('immun', 'systemnnwuhancoronavirusnnyearold'): 1.0, ('systemnnwuhancoronavirusnnyearold', 'italian'): 1.0, ('italian', 'man'): 1.0, ('man', 'born'): 1.0, ('born', 'spanish'): 1.0, ('spanish', 'flu'): 1.0, ('flu', 'pandem'): 1.0, ('pandem', 'surviv'): 1.0, ('surviv', 'coroxexxa'): 1.0, ('joydeepghosh', 'universityofhyderabad'): 1.0, ('universityofhyderabad', 'faculti'): 0.6666666666666666, ('faculti', 'develop'): 1.0, ('develop', 'potenti'): 1.0, ('potenti', 'vaccin'): 1.0, ('vaccin', 'candid'): 1.0, ('candid', 'against'): 1.0, ('against', 'coronaviru'): 0.5, ('coronaviru', 'hope'): 1.0, ('hope', 'bring'): 1.0, ('bring', 'lightxexxa'): 1.0, ('janedryden', 'are'): 1.0, ('are', 'victim'): 0.3333333333333333, ('victim', 'hate'): 1.0, ('hate', 'crime'): 1.0, ('crime', 'wuhancoronaviru'): 0.0625, ('wuhancoronaviru', 'chinesecoronaviru'): 1.0, ('chinesecoronaviru', 'we'): 0.6666666666666666, ('we', 'shouldnt'): 1.0, ('shouldnt', 'blame'): 0.4, ('blame', 'random'): 1.0, ('random', 'chine'): 0.25, ('chine', 'peoxexxa'): 1.0, ('solomonyu', 'did'): 1.0, ('did', 'chine'): 0.25, ('chine', 'mobil'): 1.0, ('mobil', 'carrier'): 1.0, ('carrier', 'show'): 1.0, ('show', 'increas'): 1.0, ('increas', 'user'): 1.0, ('user', 'if'): 0.3333333333333333, ('if', 'not'): 1.0, ('not', 'scenario'): 1.0, ('scenario', 'pay'): 1.0, ('pay', 'cell'): 1.0, ('cell', 'phone'): 1.0, ('phone', 'billsxexxa'): 1.0, ('hoccgoomus', 'first'): 0.5, ('first', 'u'): 0.5, ('u', 'italyxfxfxx'): 1.0, ('italyxfxfxx', 'the'): 0.09090909090909091, ('the', 'tri'): 0.5, ('tri', 'put'): 0.5, ('put', 'blame'): 0.2, ('blame', 'countri'): 0.5, ('countri', 'faster'): 1.0, ('faster', 'truth'): 0.06666666666666667, ('truth', 'spreadnnthi'): 1.0, ('spreadnnthi', 'propxexxa'): 1.0, ('rollypoli', 'stevescalis'): 1.0, ('stevescalis', 'nanc'): 1.0, ('nanc', 'wast'): 1.0, ('wast', 'dec'): 1.0, ('dec', 'feb'): 1.0, ('feb', 'th'): 1.0, ('th', 'shampeach'): 1.0, ('shampeach', 'instead'): 1.0, ('instead', 'prepar'): 0.5, ('prepar', 'wuhancoronaviru'): 0.03125, ('hwyoungg', 'wilfredchan'): 1.0, ('wilfredchan', 'bearmui'): 1.0, ('bearmui', 'taiwan'): 0.2, ('taiwan', 'avoid'): 1.0, ('avoid', 'first'): 0.5, ('first', 'round'): 1.0, ('round', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'outbreak'): 1.0, ('outbreak', 'earli'): 1.0, ('earli', 'action'): 0.3333333333333333, ('action', 'rather'): 1.0, ('rather', 'ccpxexxa'): 1.0, ('aniilai', 'no'): 1.0, ('no', 'privileg'): 1.0, ('privileg', 'who'): 0.13333333333333333, ('who', 'would'): 1.0, ('would', 'believ'): 1.0, ('believ', 'silli'): 1.0, ('silli', 'wordsnboth'): 1.0, ('wordsnboth', 'hkgov'): 1.0, ('hkgov', 'fehd'): 1.0, ('fehd', 'amp'): 0.4, ('amp', 'hkpoliceterrorist'): 1.0, ('hkpoliceterrorist', 'whi'): 1.0, ('whi', 'diff'): 1.0, ('diff', 'presentationnfxexxa'): 1.0, ('peopleschamp', 'plot'): 1.0, ('plot', 'twist'): 0.5, ('twist', 'the'): 0.09090909090909091, ('the', 'real'): 1.0, ('real', 'racist'): 1.0, ('racist', 'medium'): 0.07142857142857142, ('medium', 'outlet'): 1.0, ('outlet', 'quickli'): 1.0, ('quickli', 'jump'): 0.07692307692307693, ('jump', 'call'): 1.0, ('call', 'everyth'): 1.0, ('everyth', 'racistnnchineseviru'): 1.0, ('racistnnchineseviru', 'chinesewxexxa'): 1.0, ('britishk', 'ezracheungtoto'): 1.0, ('ezracheungtoto', 'who'): 0.06666666666666667, ('who', 'doe'): 0.5, ('doe', 'who'): 0.06666666666666667, ('who', 'stand'): 1.0, ('stand', 'wuhanhealthorganis'): 1.0, ('wuhanhealthorganis', 'what'): 0.5, ('what', 'differ'): 1.0, ('differ', 'bruce'): 0.5, ('bruce', 'aylward'): 1.0, ('aylward', 'amp'): 0.2, ('amp', 'drtedro'): 1.0, ('drtedro', 'seexexxa'): 1.0, ('benlukkk', 'anderscorr'): 1.0, ('anderscorr', 'if'): 0.3333333333333333, ('if', 'itali'): 1.0, ('itali', 'didnxexxt'): 1.0, ('didnxexxt', 'permit'): 1.0, ('permit', 'chine'): 0.25, ('chine', 'citizen'): 1.0, ('citizen', 'go'): 0.5, ('go', 'begin'): 1.0, ('begin', 'chineseviru'): 1.0, ('chineseviru', 'go'): 0.5, ('go', 'xfxfxxaexfxfxxb'): 1.0, ('xfxfxxaexfxfxxb', 'wuhanxexxa'): 1.0, ('bare', 'victim'): 0.3333333333333333, ('random', 'chinxexxa'): 1.0, ('chinxexxa', 'httpstcovhtujclqxn'): 1.0, ('drmartyfox', 'just'): 1.0, ('just', 'like'): 0.3333333333333333, ('like', 'they'): 0.5, ('they', 'suddenli'): 0.5, ('suddenli', 'find'): 1.0, ('find', 'elect'): 1.0, ('elect', 'ballotsnnth'): 1.0, ('ballotsnnth', 'democrat'): 0.5, ('democrat', 'mob'): 1.0, ('mob', 'aka'): 1.0, ('aka', 'the'): 0.09090909090909091, ('the', 'seiu'): 1.0, ('seiu', 'union'): 1.0, ('union', 'suddenli'): 0.5, ('find', 'mysteri'): 1.0, ('mysteri', 'stash'): 1.0, ('stash', 'of'): 1.0, ('of', 'mixexxa'): 1.0, ('bnufsaid', 'glcarlstrom'): 0.5, ('gene', 'editxexxa'): 1.0, ('editxexxa', 'httpstcoqgtepvsaog'): 1.0, ('t', 'joydeepghosh'): 0.5, ('bthi', 'wonxexxt'): 1.0, ('wonxexxt', 'forgotten'): 1.0, ('forgotten', 'end'): 1.0, ('end', 'day'): 0.04, ('day', 'bill'): 1.0, ('bill', 'come'): 0.5, ('come', 'who'): 0.06666666666666667, ('who', 'wholiedpeopledi'): 1.0, ('wholiedpeopledi', 'wuhanvirusxexxa'): 1.0, ('wuhanvirusxexxa', 'httpstcocxagccfab'): 1.0, ('britishk', 'hkworldciti'): 1.0, ('hkworldciti', 'who'): 0.06666666666666667, ('rthknew', 'doe'): 0.5, ('doe', 'fear'): 1.0, ('fear', 'applaud'): 1.0, ('applaud', 'taiwan'): 0.2, ('taiwan', 'success'): 1.0, ('success', 'combat'): 0.3333333333333333, ('combat', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'we'): 0.3333333333333333, ('we', 'noxexxa'): 1.0, ('buniversityofhyderabad', 'faculti'): 0.3333333333333333, ('hope', 'bringsxexxa'): 1.0, ('bringsxexxa', 'httpstcoajapkymvk'): 1.0, ('bgten', 'prasenj'): 1.0, ('prasenj', 'ask'): 0.25, ('ask', 'question'): 1.0, ('question', 'wuhancoronaviru'): 0.0625, ('wuhancoronaviru', 'chinaviru'): 1.0, ('chinaviru', 'covid'): 0.4, ('covid', 'architect'): 1.0, ('architect', 'ccp'): 0.6666666666666666, ('ccp', 'propaganda'): 1.0, ('propaganda', 'war'): 0.5, ('war', 'spokxexxa'): 1.0, ('cherri', 'nytim'): 1.0, ('nytim', 'ccp'): 0.3333333333333333, ('ccp', 'amp'): 0.2, ('amp', 'russia'): 1.0, ('russia', 'twist'): 0.5, ('twist', 'fact'): 0.5, ('fact', 'tri'): 0.5, ('tri', 'best'): 1.0, ('best', 'brainwash'): 1.0, ('brainwash', 'peopl'): 0.0625, ('peopl', 'pretend'): 1.0, ('pretend', 'victim'): 0.3333333333333333, ('victim', 'wuhancoxexxa'): 1.0, ('bwbyeat', 'who'): 0.06666666666666667, ('who', 'taiwan'): 0.2, ('taiwan', 'amp'): 0.2, ('amp', 'ppl'): 1.0, ('ppl', 'dont'): 1.0, ('dont', 'need'): 1.0, ('need', 'who'): 0.06666666666666667, ('who', 'public'): 1.0, ('public', 'health'): 0.3333333333333333, ('health', 'advic'): 0.5, ('advic', 'anywaynhttpstcoibuxndntxexxa'): 1.0, ('anywaynhttpstcoibuxndntxexxa', 'httpstcoisuxrbghwr'): 1.0, ('bbsrbuzz', 'the'): 0.09090909090909091, ('the', 'entir'): 1.0, ('entir', 'campu'): 1.0, ('campu', 'driem'): 1.0, ('driem', 'includ'): 1.0, ('includ', 'four'): 1.0, ('four', 'boy'): 1.0, ('boy', 'hostel'): 0.5, ('hostel', 'room'): 1.0, ('room', 'girl'): 1.0, ('girl', 'hostel'): 0.5, ('room', 'academ'): 1.0, ('academ', 'blocksxexxa'): 1.0, ('pennyrelgit', 'repgallagh'): 1.0, ('repgallagh', 'noth'): 0.5, ('noth', 'chang'): 1.0, ('chang', 'fact'): 0.5, ('fact', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'come'): 0.5, ('come', 'chinazi'): 1.0, ('chinazi', 'httpstcomctltwdg'): 1.0, ('zoechanhongkong', 'in'): 1.0, ('in', 'interview'): 1.0, ('interview', 'rthk'): 1.0, ('rthk', 'bruce'): 0.5, ('bruce', 'alyward'): 1.0, ('alyward', 'who'): 0.06666666666666667, ('who', 'ask'): 0.25, ('ask', 'reconsid'): 1.0, ('reconsid', 'taiwanxexx'): 1.0, ('taiwanxexx', 'membership'): 1.0, ('membership', 'given'): 1.0, ('given', 'good'): 1.0, ('good', 'perforxexxa'): 1.0, ('bprasenj', 'ask'): 0.25, ('ccp', 'propagandaxexxa'): 1.0, ('propagandaxexxa', 'httpstcooknagkzkjt'): 1.0, ('bactual', 'democrat'): 0.5, ('democrat', 'practic'): 0.5, ('practic', 'social'): 0.5, ('distanc', 'move'): 1.0, ('move', 'canada'): 1.0, ('canada', 'wuhancoronaviru'): 0.0625, ('bthi', 'hospit'): 1.0, ('hospit', 'seriou'): 1.0, ('seriou', 'manag'): 1.0, ('manag', 'problem'): 1.0, ('problem', 'if'): 0.3333333333333333, ('if', 'doctor'): 1.0, ('doctor', 'said'): 0.3333333333333333, ('said', 'true'): 1.0, ('true', 'disclos'): 1.0, ('disclos', 'info'): 1.0, ('info', 'thxexxa'): 1.0, ('thxexxa', 'httpstcorujafbq'): 1.0, ('bandrew', 'cuomo'): 1.0, ('cuomo', 'practic'): 0.5, ('teresaw', 'senrickscott'): 1.0, ('senrickscott', 'the'): 0.09090909090909091, ('the', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'alarm'): 1.0, ('alarm', 'world'): 0.3333333333333333, ('world', 'china'): 0.07692307692307693, ('china', 'unreli'): 1.0, ('unreli', 'danger'): 1.0, ('danger', 'the'): 0.09090909090909091, ('the', 'world'): 0.3333333333333333, ('world', 'mustxexxa'): 1.0, ('trumpwarroom', 'timelin'): 1.0, ('timelin', 'the'): 0.18181818181818182, ('the', 'trump'): 1.0, ('trump', 'administr'): 1.0, ('administr', 'decis'): 1.0, ('decis', 'action'): 0.6666666666666666, ('action', 'combat'): 0.6666666666666666, ('combat', 'coronaviru'): 0.3333333333333333, ('coronaviru', 'gtnhttpstcofnwkeujbb'): 1.0, ('gtnhttpstcofnwkeujbb', 'nnchinesevixexxa'): 1.0, ('bjust', 'imagin'): 0.5, ('imagin', 'world'): 0.3333333333333333, ('world', 'without'): 1.0, ('without', 'china'): 0.07692307692307693, ('china', 'le'): 1.0, ('le', 'global'): 1.0, ('global', 'warm'): 1.0, ('warm', 'a'): 0.25, ('a', 'bit'): 1.0, ('bit', 'expens'): 1.0, ('expens', 'still'): 1.0, ('still', 'better'): 0.5, ('better', 'air'): 1.0, ('air', 'benefit'): 1.0, ('benefit', 'motxexxa'): 1.0, ('motxexxa', 'httpstcodhsbopoow'): 1.0, ('bimrankhanpti', 'clarencehous'): 1.0, ('clarencehous', 'borisjohnson'): 1.0, ('borisjohnson', 'the'): 0.09090909090909091, ('the', 'blame'): 0.2, ('blame', 'lie'): 1.0, ('lie', 'china'): 0.07692307692307693, ('china', 'theyr'): 1.0, ('theyr', 'respons'): 1.0, ('respons', 'death'): 0.5, ('death', 'arouxexxa'): 1.0, ('arouxexxa', 'httpstcodltdkzv'): 1.0, ('alantonelson', 'tracyjan'): 1.0, ('tracyjan', 'nation'): 1.0, ('nation', 'univers'): 1.0, ('univers', 'healthcar'): 1.0, ('healthcar', 'wouldv'): 1.0, ('wouldv', 'better'): 0.5, ('better', 'prepar'): 0.5, ('prepar', 'u'): 0.5, ('u', 'deal'): 1.0, ('deal', 'ccpviru'): 1.0, ('ccpviru', 'serious'): 1.0, ('serious', 'like'): 0.3333333333333333, ('like', 'ixexxa'): 1.0, ('lawmic', 'nathanlawkc'): 1.0, ('nathanlawkc', 'thecantonesegod'): 1.0, ('thecantonesegod', 'scrap'): 1.0, ('scrap', 'who'): 0.13333333333333333, ('who', 'rebrand'): 1.0, ('rebrand', 'cho'): 1.0, ('cho', 'china'): 0.15384615384615385, ('china', 'health'): 0.6666666666666666, ('health', 'organ'): 1.0, ('organ', 'now'): 0.4, ('now', 'mission'): 1.0, ('mission', 'make'): 1.0, ('make', 'wixexxa'): 1.0, ('bpeopl', 'scare'): 1.0, ('scare', 'liberti'): 0.5, ('liberti', 'dissolv'): 1.0, ('dissolv', 'marklevinshow'): 1.0, ('marklevinshow', 'aptli'): 1.0, ('aptli', 'put'): 0.5, ('put', 'wuhanviru'): 1.0, ('wuhanviru', 'wuhancoronaviru'): 0.03125, ('bmisguid', 'drug'): 1.0, ('drug', 'advic'): 0.5, ('advic', 'covid'): 0.2, ('covid', 'ibuprofen'): 1.0, ('ibuprofen', 'nsaid'): 1.0, ('nsaid', 'intervent'): 1.0, ('intervent', 'wuhancoronaviru'): 0.03125, ('outbreak', 'clusterxexxa'): 1.0, ('clusterxexxa', 'httpstcojviwvkxr'): 1.0, ('bevid', 'china'): 0.07692307692307693, ('china', 'sponsor'): 1.0, ('sponsor', 'china'): 0.07692307692307693, ('china', 'must'): 1.0, ('must', 'held'): 1.0, ('held', 'account'): 1.0, ('account', 'spread'): 1.0, ('spread', 'coronaviru'): 0.16666666666666666, ('coronaviru', 'videoxexxa'): 1.0, ('videoxexxa', 'httpstcomjkuydtzpf'): 1.0, ('roofmonqey', 'ahhh'): 1.0, ('ahhh', 'hey'): 1.0, ('hey', 'china'): 0.07692307692307693, ('china', 'death'): 0.5, ('death', 'toll'): 1.0, ('toll', 'wuhancoronaviru'): 0.03125, ('wuhancoronaviru', 'xfxfxxnnwwgwga'): 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVMRwKpt70j3",
        "colab_type": "code",
        "outputId": "ceed61da-2880-4efe-b33e-cfe368bedd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# (3) Extract all the noun phrases and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets).\n",
        "import pandas as pd\n",
        "import csv\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nouns_lst=[]\n",
        "data_nouns={}\n",
        "for i in data[\"tweet_data\"]:\n",
        "    words=word_tokenize(i)\n",
        "    nouns_data=list(filter(lambda x : x[1]==\"NN\" ,nltk.pos_tag(words)))\n",
        "#     print(nouns_data)\n",
        "    values=list(map(lambda x: x[0], nouns_data))\n",
        "    data_nouns[i]=values\n",
        "    nouns_lst=nouns_lst+values\n",
        "nouns_set=set(nouns_lst)\n",
        "# print(nouns_lst)\n",
        "df = pd.DataFrame(index=data[\"tweet_data\"],columns=nouns_set)\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "    for noun in nouns_set:\n",
        "      df.at[data[\"tweet_data\"][i],noun]=(data_nouns[data[\"tweet_data\"][i]].count(noun))/(nouns_lst.count(noun))\n",
        "print(df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "                                                   wuhancoronaviru  ... countri\n",
            "tweet_data                                                          ...        \n",
            "rajeevsrinivasa karnataka enforc cordonsanitair...       0.0357143  ...       0\n",
            "nikkimiumiu a hongkong femal polic infect wuhan...       0.0357143  ...       0\n",
            "allmui hkpolic use ruler measur distanc tabl ba...               0  ...       0\n",
            "mymonke chinaliedpeopledi nnaround day ago basi...               0  ...       0\n",
            "rajeevsrinivasa karnataka enforc cordonsanitair...       0.0357143  ...       0\n",
            "...                                                            ...  ...     ...\n",
            "bevid china sponsor china must held account spr...               0  ...       0\n",
            "roofmonqey ahhh hey china death toll wuhancoron...       0.0357143  ...       0\n",
            "mymonke chinaliedpeopledi nnaround day ago basi...               0  ...       0\n",
            "therealcook now that immun systemnnwuhancoronav...               0  ...       0\n",
            "hyltonrobin xfxfxaxa break fox busi network fir...               0  ...       0\n",
            "\n",
            "[100 rows x 318 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkFYFm8q70j8",
        "colab_type": "text"
      },
      "source": [
        "### Question 2: Undersand TF-IDF and Document representation\n",
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program:\n",
        "\n",
        "(1) To build the documents-terms weights (tf*idf) matrix bold text.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUms7KRt70j9",
        "colab_type": "code",
        "outputId": "0f298837-32fe-42c7-d625-47ddbaf8a7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#(1) To build the documents-terms weights (tf*idf) matrix bold text.\n",
        "import math\n",
        "\n",
        "tfidf_words_lst=[]\n",
        "tfidf_data={}\n",
        "for i in data[\"tweet_data\"]:\n",
        "    words=word_tokenize(i)\n",
        "    nouns_data=list(nltk.pos_tag(words))\n",
        "#     print(nouns_data)\n",
        "    values=list(map(lambda x: x[0], nouns_data))\n",
        "    tfidf_data[i]=values\n",
        "    nouns_lst=nouns_lst+values\n",
        "nouns_set=set(nouns_lst)\n",
        "\n",
        "tdidf = pd.DataFrame(index=data[\"tweet_data\"],columns=nouns_set)\n",
        "\n",
        "for i in range(len(df)):\n",
        "    for noun in nouns_set:\n",
        "      tdidf.at[data[\"tweet_data\"][i],noun]=(tfidf_data[data[\"tweet_data\"][i]].count(noun))*(math.log(len(data[\"tweet_data\"])/(nouns_lst.count(noun))))\n",
        "print(df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   wuhancoronaviru  ... countri\n",
            "tweet_data                                                          ...        \n",
            "rajeevsrinivasa karnataka enforc cordonsanitair...       0.0357143  ...       0\n",
            "nikkimiumiu a hongkong femal polic infect wuhan...       0.0357143  ...       0\n",
            "allmui hkpolic use ruler measur distanc tabl ba...               0  ...       0\n",
            "mymonke chinaliedpeopledi nnaround day ago basi...               0  ...       0\n",
            "rajeevsrinivasa karnataka enforc cordonsanitair...       0.0357143  ...       0\n",
            "...                                                            ...  ...     ...\n",
            "bevid china sponsor china must held account spr...               0  ...       0\n",
            "roofmonqey ahhh hey china death toll wuhancoron...       0.0357143  ...       0\n",
            "mymonke chinaliedpeopledi nnaround day ago basi...               0  ...       0\n",
            "therealcook now that immun systemnnwuhancoronav...               0  ...       0\n",
            "hyltonrobin xfxfxaxa break fox busi network fir...               0  ...       0\n",
            "\n",
            "[100 rows x 318 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP-y6Cja70kB",
        "colab_type": "code",
        "outputId": "565a91d7-8a0c-44a6-d0d1-7b1dfa888535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using cosine similarity.\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "queryText = \"This text is to test the cosine similarity witht the tweets data\"\n",
        "cosine_lst=[]\n",
        "for tweetText in data[\"tweet_data\"]:\n",
        "    vector1 = text_to_vector(tweetText)\n",
        "    vector2 = text_to_vector(queryText)\n",
        "    cosine = get_cosine(vector1, vector2)\n",
        "    cosine_lst.append(cosine)\n",
        "print(\"Cosine similarity for the given text with the tweets data:\")\n",
        "print(cosine_lst)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity for the given text with the tweets data:\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1889822365046136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15430334996209194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14824986333222026, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1091089451179962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12262786789699315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672612419124244, 0.0, 0.16116459280507606, 0.0, 0.0, 0.15430334996209194, 0.0, 0.0, 0.0, 0.16116459280507606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuftonMW70kE",
        "colab_type": "text"
      },
      "source": [
        "### Question 3: Create your own training and evaluation data for sentiment analysis\n",
        "(15 points). You dodn't need to write program for this question! Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsj1fk8e70kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "from textblob import TextBlob \n",
        "\n",
        "def clean_tweet(tweet): \n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
        "  \n",
        "def get_tweet_sentiment(tweet): \n",
        "        ''' \n",
        "        Utility function to classify sentiment of passed tweet \n",
        "        using textblob's sentiment method \n",
        "        '''\n",
        "        # create TextBlob object of passed tweet text \n",
        "        analysis = TextBlob(clean_tweet(tweet)) \n",
        "        # set sentiment \n",
        "        if analysis.sentiment.polarity > 0: \n",
        "            return 'positive'\n",
        "        elif analysis.sentiment.polarity == 0: \n",
        "            return 'neutral'\n",
        "        else: \n",
        "            return 'negative'\n",
        "filePointer = open(\"sentimetn_analysis_file.txt\",\"a\")\n",
        "                               \n",
        "sentiment_data={}  \n",
        "counter=1\n",
        "for tweet in data[\"tweet_data\"]:\n",
        "#     sentiment_data[tweet]=get_tweet_sentiment(tweet)\n",
        "    sentiment_data=str(counter)+\",\"+str(tweet)+\",\"+str(get_tweet_sentiment(tweet))+\"\\n\"\n",
        "    filePointer.write(sentiment_data)\n",
        "    counter=counter+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r988QGFMBDS0",
        "colab_type": "text"
      },
      "source": [
        "Sentiment Analysis Test Data Github link :\n",
        "https://github.com/psameni/Pranaya_INFO5731_Spring2020/blob/master/sentimetn_analysis_file.txt"
      ]
    }
  ]
}